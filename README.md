# ì´ìŠˆ ìë™ ìƒì„±ê¸° ì„¤ëª…

create_issue.exeì™€ ê°™ì€ ìœ„ì¹˜ì— env íŒŒì¼ì„ ìœ„ì¹˜ì‹œí‚¨ í›„ ì‹¤í–‰í•©ë‹ˆë‹¤.
ì´ìŠˆ ë‚´ìš© ë° ì‘ì—…ë‚´ìš©ë“¤ì„ ì‘ì„±í•œ í›„ enterë¥¼ ì…ë ¥í•˜ë©´ 5~10ì´ˆ ë’¤ ìë™ìœ¼ë¡œ ì´ìŠˆ ë‚´ìš©ì´ ìƒì„±ë©ë‹ˆë‹¤.
í™•ì¸í›„ ì í•©í•˜ë‹¤ë©´ y(Y)ë¥¼ ì…ë ¥í•˜ë©´ ì´ìŠˆ ë° ë¸Œëœì¹˜ê°€ ìë™ìœ¼ë¡œ ìƒì„±ë©ë‹ˆë‹¤.
AI hub 
https://www.aihub.or.kr/aihubdata/data/view.do?currMenu=115&dataSetSn=597&topMenu=100&utm_source=chatgpt.com

*í•­ìƒ ìœ„ì— ì‹¤í–‰í•  ê²ƒ
import os
os.environ["CUDA_DEVICE_ORDER"] = "PCI_BUS_ID"
os.environ["CUDA_VISIBLE_DEVICES"] = "2" 
--------------------
* ë‹¤ìš´ë¡œë“œ ì½”ë“œ
./aihubshell -mode d -datasetkey 597 -filekey 509344 -aihubapikey '1C24F55B-D5C2-41D2-B59F-F66122379825'
----------------------
*íŒ€ í”„ë¡œì„¸ìŠ¤ ì¡°íšŒí•˜ê¸°
$ps -ef|grep k12e203
*ì„œë²„ ë¦¬ì†ŒìŠ¤ í™•ì¸
$htop ì‹¤í–‰
--------------------------
ìœ„ì¹˜	íŒŒì¼ëª…
1.Training/ì›ì²œë°ì´í„°/	
TS_ì°¨ëŒ€ì°¨_ì´ë¯¸ì§€_Tìí˜•êµì°¨ë¡œ.zip
1.Training/ë¼ë²¨ë§ë°ì´í„°/	
TL_ì°¨ëŒ€ì°¨_ì´ë¯¸ì§€_Tìí˜•êµì°¨ë¡œ.zip
2.Validation/ì›ì²œë°ì´í„°_231108_add/	
VS_ì°¨ëŒ€ì°¨_ì´ë¯¸ì§€_Tìí˜•êµì°¨ë¡œ.zip
2.Validation/ë¼ë²¨ë§ë°ì´í„°_231108_add/	
VL_ì°¨ëŒ€ì°¨_ì´ë¯¸ì§€_Tìí˜•êµì°¨ë¡œ.zip
--------------------------
ë‹¤ìš´ë¡œë“œ í›„ ì••ì¶•í’€ê¸°
import zipfile
import os
import shutil

# ì••ì¶• íŒŒì¼ ê²½ë¡œ
train_image_zip = '/home/j-k12e203/traffic_data/095.êµí†µì‚¬ê³ _ì˜ìƒ_ë°ì´í„°/01.ë°ì´í„°/1.Training/ì›ì²œë°ì´í„°/TS_ì°¨ëŒ€ì°¨_ì´ë¯¸ì§€_Tìí˜•êµì°¨ë¡œ.zip'
train_label_zip = '/home/j-k12e203/traffic_data/095.êµí†µì‚¬ê³ _ì˜ìƒ_ë°ì´í„°/01.ë°ì´í„°/1.Training/ë¼ë²¨ë§ë°ì´í„°/TL_ì°¨ëŒ€ì°¨_ì´ë¯¸ì§€_Tìí˜•êµì°¨ë¡œ.zip'
val_image_zip = '/home/j-k12e203/traffic_data/095.êµí†µì‚¬ê³ _ì˜ìƒ_ë°ì´í„°/01.ë°ì´í„°/2.Validation/ì›ì²œë°ì´í„°_231108_add/VS_ì°¨ëŒ€ì°¨_ì´ë¯¸ì§€_Tìí˜•êµì°¨ë¡œ.zip'
val_label_zip = '/home/j-k12e203/traffic_data/095.êµí†µì‚¬ê³ _ì˜ìƒ_ë°ì´í„°/01.ë°ì´í„°/2.Validation/ë¼ë²¨ë§ë°ì´í„°_231108_add/VL_ì°¨ëŒ€ì°¨_ì´ë¯¸ì§€_Tìí˜•êµì°¨ë¡œ.zip'

# ì„ì‹œ ì••ì¶• í•´ì œ í´ë”
extracted_dir = '/home/j-k12e203/traffic_data/extracted'
os.makedirs(extracted_dir, exist_ok=True)

# ìµœì¢… ì €ì¥ í´ë”
final_dirs = {
    'train_images': '/home/j-k12e203/traffic_data/train/images/t_junction',
    'train_labels': '/home/j-k12e203/traffic_data/train/labels/t_junction',
    'val_images': '/home/j-k12e203/traffic_data/val/images/t_junction',
    'val_labels': '/home/j-k12e203/traffic_data/val/labels/t_junction',
}

for path in final_dirs.values():
    os.makedirs(path, exist_ok=True)

# ì••ì¶• í•´ì œ í•¨ìˆ˜
def unzip_and_move(zip_path, dest_folder):
    with zipfile.ZipFile(zip_path, 'r') as zip_ref:
        zip_ref.extractall(dest_folder)

# ì••ì¶• í•´ì œ
unzip_and_move(train_image_zip, f'{extracted_dir}/train_images_tj')
unzip_and_move(train_label_zip, f'{extracted_dir}/train_labels_tj')
unzip_and_move(val_image_zip, f'{extracted_dir}/val_images_tj')
unzip_and_move(val_label_zip, f'{extracted_dir}/val_labels_tj')

print("âœ… ì••ì¶• í•´ì œ ì™„ë£Œ")

# íŒŒì¼ ì´ë™
def move_files(src_dir, dst_dir, extension):
    for root, _, files in os.walk(src_dir):
        for file in files:
            if file.endswith(extension):
                src_path = os.path.join(root, file)
                dst_path = os.path.join(dst_dir, file)
                
                # ì´ë¯¸ ê°™ì€ ì´ë¦„ íŒŒì¼ì´ ìˆìœ¼ë©´ ì‚­ì œ
                if os.path.exists(dst_path):
                    os.remove(dst_path)
                
                shutil.move(src_path, dst_dir)

# íŒŒì¼ ì´ë™ ì‹¤í–‰
move_files(f'{extracted_dir}/train_images_tj', final_dirs['train_images'], '.png')
move_files(f'{extracted_dir}/train_labels_tj', final_dirs['train_labels'], '.json')
move_files(f'{extracted_dir}/val_images_tj', final_dirs['val_images'], '.png')
move_files(f'{extracted_dir}/val_labels_tj', final_dirs['val_labels'], '.json')

print("âœ… íŒŒì¼ ì´ë™ ì™„ë£Œ!")

# (ì„ íƒ) ì„ì‹œ í´ë” ì •ë¦¬
shutil.rmtree(extracted_dir)
print("âœ… ì„ì‹œ í´ë” ì‚­ì œ ì™„ë£Œ!")
---------------------
ìµœì¢… í´ë” ì ê²€ ì½”ë“œ
import os

# í´ë” ê²½ë¡œ
paths = {
    'train_images_tj': '/home/j-k12e203/traffic_data/train/images/t_junction',
    'train_labels_tj': '/home/j-k12e203/traffic_data/train/labels/t_junction',
    'val_images_tj': '/home/j-k12e203/traffic_data/val/images/t_junction',
    'val_labels_tj': '/home/j-k12e203/traffic_data/val/labels/t_junction',
}

# ê° í´ë” íŒŒì¼ ê°œìˆ˜ í™•ì¸
for name, path in paths.items():
    if os.path.exists(path):
        files = os.listdir(path)
        num_files = len(files)
        print(f"âœ… {name} í´ë”ì— {num_files}ê°œ íŒŒì¼ ì¡´ì¬")
    else:
        print(f"âŒ {name} í´ë”ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŒ (ì˜¤ë¥˜!)")
---------------------------
COCO í¬ë§· ë³€í™˜ ì½”ë“œ
import os
import json
import glob

# ê²½ë¡œ ì„¤ì •
train_label_dir = '/home/j-k12e203/traffic_data/train/labels/t_junction'
val_label_dir = '/home/j-k12e203/traffic_data/val/labels/t_junction'

output_train_coco = '/home/j-k12e203/traffic_data/train_coco.json'
output_val_coco = '/home/j-k12e203/traffic_data/val_coco.json'

# í´ë˜ìŠ¤ ë§¤í•‘
category_mapping = {
    'vehicle': 1,
    'pedestrian': 2,
    'traffic-light-red': 3,
    'traffic-light-green': 4,
    'traffic-light-yellow': 5,
    'traffic-sign': 6,
}

categories = [
    {"id": 1, "name": "vehicle"},
    {"id": 2, "name": "pedestrian"},
    {"id": 3, "name": "traffic-light-red"},
    {"id": 4, "name": "traffic-light-green"},
    {"id": 5, "name": "traffic-light-yellow"},
    {"id": 6, "name": "traffic-sign"},
]

def convert_to_coco(label_dir, output_json):
    images = []
    annotations = []
    annotation_id = 0
    image_id = 0

    label_files = sorted(glob.glob(os.path.join(label_dir, '*.json')))

    for label_file in label_files:
        with open(label_file, 'r', encoding='utf-8') as f:
            label_data = json.load(f)

        file_name = label_data['file_name']
        width = label_data['width']
        height = label_data['height']

        images.append({
            "id": image_id,
            "file_name": file_name,
            "width": width,
            "height": height,
        })

        for obj in label_data.get('objects', []):
            category = obj['category']
            if category not in category_mapping:
                continue

            bbox = obj['bbox']
            x, y, w, h = bbox

            annotations.append({
                "id": annotation_id,
                "image_id": image_id,
                "category_id": category_mapping[category],
                "bbox": [x, y, w, h],
                "area": w * h,
                "iscrowd": 0,
            })
            annotation_id += 1

        image_id += 1

    coco_format = {
        "info": {},
        "licenses": [],
        "images": images,
        "annotations": annotations,
        "categories": categories,
    }

    with open(output_json, 'w', encoding='utf-8') as f:
        json.dump(coco_format, f, ensure_ascii=False, indent=4)
    print(f"âœ… COCO íŒŒì¼ ìƒì„± ì™„ë£Œ: {output_json}")

# ë³€í™˜ ì‹¤í–‰
convert_to_coco(train_label_dir, output_train_coco)
convert_to_coco(val_label_dir, output_val_coco)
---------------------------
COCO í¬ë§· í™•ì¸ ì½”ë“œ
import json

# ê²½ë¡œ ì„¤ì •
train_coco_path = '/home/j-k12e203/traffic_data/train_coco.json'
val_coco_path = '/home/j-k12e203/traffic_data/val_coco.json'

def check_coco_format(coco_json_path):
    with open(coco_json_path, 'r', encoding='utf-8') as f:
        data = json.load(f)

    print(f"âœ… {coco_json_path} í™•ì¸ ê²°ê³¼:")
    print(f"  ğŸ“¦ images ìˆ˜: {len(data.get('images', []))}")
    print(f"  ğŸ·ï¸ annotations ìˆ˜: {len(data.get('annotations', []))}")
    print(f"  ğŸ·ï¸ categories ìˆ˜: {len(data.get('categories', []))}")
    print()

# ì²´í¬ ì‹¤í–‰
check_coco_format(train_coco_path)
check_coco_format(val_coco_path)
----------------------------------
COCO => Yolo í¬ë§· ë³€í™˜
import os
import json
from tqdm import tqdm

# ê²½ë¡œ ì„¤ì •
train_coco_path = '/home/j-k12e203/traffic_data/train_coco.json'
val_coco_path = '/home/j-k12e203/traffic_data/val_coco.json'

train_output_dir = '/home/j-k12e203/traffic_data/yolo_labels/train/'
val_output_dir = '/home/j-k12e203/traffic_data/yolo_labels/val/'

# ë””ë ‰í† ë¦¬ ìƒì„±
os.makedirs(train_output_dir, exist_ok=True)
os.makedirs(val_output_dir, exist_ok=True)

# ë³€í™˜ í•¨ìˆ˜
def convert_coco_to_yolo(coco_path, output_dir):
    with open(coco_path, 'r') as f:
        coco = json.load(f)

    # ì´ë¯¸ì§€ ID -> íŒŒì¼ ì´ë¦„ ë§¤í•‘
    id_to_filename = {img['id']: img['file_name'] for img in coco['images']}

    # ì¶œë ¥ìš© ë”•ì…”ë„ˆë¦¬ ì´ˆê¸°í™”
    yolo_labels = {filename: [] for filename in id_to_filename.values()}

    # ì–´ë…¸í…Œì´ì…˜ ë³€í™˜
    for ann in tqdm(coco['annotations'], desc=f"Processing {os.path.basename(coco_path)}"):
        image_id = ann['image_id']
        bbox = ann['bbox']
        category_id = ann['category_id']

        file_name = id_to_filename[image_id]

        # bbox ë³€í™˜ (x_center, y_center, width, height), ê°’ì€ ì´ë¯¸ì§€ í¬ê¸°ì— ë§ì¶°ì„œ 0~1ë¡œ ì •ê·œí™”
        img_width = 1920
        img_height = 1080

        x_min, y_min, width, height = bbox
        x_center = (x_min + width / 2) / img_width
        y_center = (y_min + height / 2) / img_height
        width /= img_width
        height /= img_height

        # YOLO í¬ë§·: category_id x_center y_center width height
        yolo_labels[file_name].append(f"{category_id} {x_center:.6f} {y_center:.6f} {width:.6f} {height:.6f}")

    # ì €ì¥
    for file_name, labels in yolo_labels.items():
        txt_file = os.path.splitext(file_name)[0] + '.txt'
        txt_path = os.path.join(output_dir, txt_file)
        with open(txt_path, 'w') as f:
            f.write('\n'.join(labels))

# ë³€í™˜ ì‹¤í–‰
convert_coco_to_yolo(train_coco_path, train_output_dir)
convert_coco_to_yolo(val_coco_path, val_output_dir)

print("âœ… ë³€í™˜ ì™„ë£Œ! YOLO í¬ë§· ë¼ë²¨ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.")
print(f"Train labels ìœ„ì¹˜: {train_output_dir}")
print(f"Val labels ìœ„ì¹˜: {val_output_dir}")
------------------
yolo ë³€í™˜ íŒŒì¼ êµ¬ì¡°
/home/j-k12e203/traffic_data/yolo_labels/
    â”œâ”€â”€ train/
    â”‚   â”œâ”€â”€ 001_147_001.txt
    â”‚   â”œâ”€â”€ 001_147_003.txt
    â”‚   â””â”€â”€ ...
    â””â”€â”€ val/
        â”œâ”€â”€ 001_147_002.txt
        â”œâ”€â”€ 001_147_010.txt
        â””â”€â”€ ...
-----------------------------
data.yaml ì½”ë“œ
nano /home/j-k12e203/traffic_data/data.yaml

path: /home/j-k12e203/traffic_data

train: train/images/t_junction
val: val/images/t_junction

nc: 6

names:
  0: vehicle
  1: pedestrian
  2: traffic-light-red
  3: traffic-light-green
  4: traffic-light-yellow
  5: traffic-sign
--------------------------
íŒŒì¼ ì´ë™ ì½”ë“œ
# YOLO txt ë¼ë²¨ ë³µì‚¬
find /home/j-k12e203/traffic_data/yolo_labels/train/ -name '*.txt' -exec cp {} /home/j-k12e203/traffic_data/train/labels/t_junction/ \;
cp /home/j-k12e203/traffic_data/yolo_labels/val/*.txt /home/j-k12e203/traffic_data/val/labels/t_junction/
--------------------------
YOLO ì‹¤í–‰ì½”ë“œ
yolo detect train data=/home/j-k12e203/traffic_data/data.yaml model=yolov8n.pt epochs=10 imgsz=640 device=2 batch=32
---------------------------
YOLO ì¶”ë¡  ê²°ê³¼ json ì €ì¥
from ultralytics import YOLO
import os
import json
from tqdm import tqdm

# 1. ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸° (ê²½ë¡œ ìˆ˜ì •)
model = YOLO('/home/j-k12e203/traffic_data/runs/detect/train7/weights/best.pt')

# 2. source í´ë” ì„¤ì • (val ë˜ëŠ” test)
source_dir = '/home/j-k12e203/traffic_data/val/images/t_junction'  # ì˜ˆì‹œ
output_json_path = './yolo_detection_results.json'

# 3. ê²°ê³¼ ì €ì¥ìš© ë¦¬ìŠ¤íŠ¸
all_results = []

# 4. source_dir ì•ˆì˜ ëª¨ë“  ì´ë¯¸ì§€ ì¶”ë¡ 
image_files = [f for f in os.listdir(source_dir) if f.endswith(('.png', '.jpg', '.jpeg'))]

for img_file in tqdm(image_files, desc="Running YOLO inference"):
    img_path = os.path.join(source_dir, img_file)
    
    # 1ì¥ ì´ë¯¸ì§€ ì¶”ë¡ 
    results = model.predict(img_path, save=False, conf=0.3, verbose=False)[0]
    
    # ì¶”ë¡  ê²°ê³¼ë¥¼ ë¦¬ìŠ¤íŠ¸ì— ì €ì¥
    detections = []
    for box in results.boxes:
        bbox = box.xyxy[0].cpu().numpy().tolist()  # [x1, y1, x2, y2]
        score = box.conf[0].cpu().item()
        cls = int(box.cls[0].cpu().item())
        
        detections.append({
            'bbox': bbox,
            'score': score,
            'class': cls,
        })
    
    all_results.append({
        'image_file': img_file,
        'detections': detections
    })

# 5. ê²°ê³¼ë¥¼ JSONìœ¼ë¡œ ì €ì¥
with open(output_json_path, 'w') as f:
    json.dump(all_results, f, indent=2)

print(f"YOLO Detection ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {output_json_path}")

-------------------------------
yolo json í˜•ì‹
[
  {
    "image_file": "example1.png",
    "detections": [
      {"bbox": [x1, y1, x2, y2], "score": 0.95, "class": 0},
      {"bbox": [x1, y1, x2, y2], "score": 0.88, "class": 2}
    ]
  },
  {
    "image_file": "example2.png",
    "detections": []
  }
]
--------------------------
tracklet ìƒì„±

import json
import os
from tqdm import tqdm

# 1. íŒŒì¼ ê²½ë¡œ ì„¤ì •
tracklets_path = './tracklets.json'
meta_folder = '/home/j-k12e203/traffic_data/val/labels/t_junction'  # (ë˜ëŠ” trainìœ¼ë¡œë„ ê°€ëŠ¥)
output_path = './tracklets_with_video_info.json'

# 2. tracklets.json ì½ê¸°
with open(tracklets_path, 'r') as f:
    tracklets = json.load(f)

# 3. ë©”íƒ€ë°ì´í„° ì½ê¸° (ëª¨ë“  íŒŒì¼ ì½ê¸°)
file2videoinfo = {}

json_files = [f for f in os.listdir(meta_folder) if f.endswith('.json')]

for json_file in tqdm(json_files, desc="Loading meta files"):
    json_path = os.path.join(meta_folder, json_file)
    with open(json_path, 'r') as f:
        meta = json.load(f)
        file_name = meta['file_name']
        video_file_name = meta['video_file_name']
        sequence_frame_number = meta['sequence_frame_number']
        file2videoinfo[file_name] = {
            'video_file_name': video_file_name,
            'sequence_frame_number': sequence_frame_number
        }

# 4. trackletsì— video info ì¶”ê°€
new_tracklets = []

for tr in tqdm(tracklets, desc="Matching video info"):
    file_name = tr['image_file']
    if file_name in file2videoinfo:
        tr['video_file_name'] = file2videoinfo[file_name]['video_file_name']
        tr['sequence_frame_number'] = file2videoinfo[file_name]['sequence_frame_number']
    else:
        tr['video_file_name'] = 'unknown'
        tr['sequence_frame_number'] = -1
    new_tracklets.append(tr)

# 5. ì €ì¥
with open(output_path, 'w') as f:
    json.dump(new_tracklets, f, indent=2)

print(f"âœ… Trackletsì— video info ì¶”ê°€ ì™„ë£Œ: {output_path}")

------------------------
Tracklet json í˜•ì‹
[
  {
    "frame_idx": 0,
    "image_file": "00001.png",
    "bbox": [100.0, 120.0, 200.0, 250.0],
    "score": 0.95,
    "class": 0,
    "track_id": 5
  },
  {
    "frame_idx": 0,
    "image_file": "00001.png",
    "bbox": [50.0, 80.0, 120.0, 150.0],
    "score": 0.91,
    "class": 2,
    "track_id": 7
  },
  ...
]
------------------------------
VTN ì‹œí€€ìŠ¤ ìƒì„± ì½”ë“œ 16í”„ë ˆì„ ê¸°ì¤€
import json
import os
from collections import defaultdict
from tqdm import tqdm

# íŒŒì¼ ê²½ë¡œ
tracklets_path = './tracklets_with_video_info.json'
output_dir = './vtn_sequences'
os.makedirs(output_dir, exist_ok=True)

# ì½ê¸°
with open(tracklets_path, 'r') as f:
    tracklets = json.load(f)

# ë¹„ë””ì˜¤ë³„ë¡œ ë¬¶ê¸°
video_dict = defaultdict(list)
for t in tracklets:
    video_dict[t['video_file_name']].append(t)

# ë¹„ë””ì˜¤ë³„ë¡œ ì²˜ë¦¬
sequence_length = 16
seq_id = 0

for video_name, tracks in tqdm(video_dict.items(), desc="Building sequences"):
    # sequence_frame_number ê¸°ì¤€ ì •ë ¬
    tracks = sorted(tracks, key=lambda x: x['sequence_frame_number'])

    # ëª¨ë“  frames ëª¨ìœ¼ê¸°
    frame_dict = defaultdict(list)
    for tr in tracks:
        frame_idx = tr['sequence_frame_number']
        frame_dict[frame_idx].append({
            'track_id': tr['track_id'],
            'bbox': tr['bbox'],
            'class': tr['class'],
            'score': tr['score'],
        })

    frame_indices = sorted(frame_dict.keys())
    
    # ìŠ¬ë¼ì´ë”© ìœˆë„ìš°ë¡œ ì‹œí€€ìŠ¤ ë§Œë“¤ê¸°
    for i in range(len(frame_indices) - sequence_length + 1):
        selected_frames = frame_indices[i:i+sequence_length]
        
        sequence = {
            'video_name': video_name,
            'start_frame': selected_frames[0],
            'frames': []
        }

        valid = True
        for fi in selected_frames:
            if fi not in frame_dict:
                valid = False
                break
            sequence['frames'].append({
                'frame_idx': fi,
                'objects': frame_dict[fi]
            })

        if valid:
            # íŒŒì¼ í•˜ë‚˜ì”© ì €ì¥
            seq_path = os.path.join(output_dir, f'seq_{seq_id:06d}.json')
            with open(seq_path, 'w') as f:
                json.dump(sequence, f, indent=2)
            seq_id += 1

print(f"âœ… VTNìš© ì‹œí€€ìŠ¤ ìƒì„± ì™„ë£Œ: {output_dir} ì•ˆì— {seq_id}ê°œ ì‹œí€€ìŠ¤ ì €ì¥ë¨")
---------------------------
ì‹œí€€ìŠ¤ json í˜•ì‹
{
  "video_name": "bb_1_160505_pedestrian_117_091",
  "start_frame": 0,
  "frames": [
    { "frame_idx": 0, "objects": [{ "track_id": 3, "bbox": [...], "class": 0, "score": 0.9 }, {...}] },
    { "frame_idx": 1, "objects": [{ "track_id": 3, "bbox": [...], "class": 0, "score": 0.91 }, {...}] },
    ...
    { "frame_idx": 15, "objects": [...] }
  ]
}
--------------------------
accident_dataset.py ì½”ë“œ 
íŒŒì¼ ìœ„ì¹˜ : vtn_accident_project/dataset
import os
import json
from torch.utils.data import Dataset

class AccidentDataset(Dataset):
    def __init__(self, sequence_dir, label_json_path, sequence_length=16, transform=None):
        self.sequence_dir = sequence_dir
        self.transform = transform
        self.sequence_length = sequence_length
        
        self.sequence_files = sorted([
            os.path.join(sequence_dir, f) for f in os.listdir(sequence_dir) if f.endswith('.json')
        ])
        
        with open(label_json_path, 'r') as f:
            label_data = json.load(f)
        
        self.video_to_label = {}
        for item in label_data:
            video_name = item['video']['video_name']
            accident_type = item['video']['traffic_accident_type']
            self.video_to_label[video_name] = accident_type

    def __len__(self):
        return len(self.sequence_files)

    def __getitem__(self, idx):
        seq_path = self.sequence_files[idx]
        with open(seq_path, 'r') as f:
            seq_data = json.load(f)

        video_name = seq_data['video_name']
        label = self.video_to_label.get(video_name, -1)

        frames = seq_data['frames']
        assert len(frames) == self.sequence_length, f"Expected {self.sequence_length} frames but got {len(frames)}"

        all_objects = []
        for frame in frames:
            objs = frame['objects']
            all_objects.append(objs)
        
        sample = {
            'objects': all_objects,
            'label': label,
            'video_name': video_name
        }
        
        if self.transform:
            sample = self.transform(sample)
        
        return sample
--------------------------------------
vtn_accident.py ì½”ë“œ
íŒŒì¼ ìœ„ì¹˜ vtn_accident_project/model/vtn_accident.py
import torch
import torch.nn as nn

class SimpleVTN(nn.Module):
    def __init__(self, num_classes=132, sequence_length=16, hidden_dim=512):
        super(SimpleVTN, self).__init__()
        
        self.sequence_length = sequence_length
        self.hidden_dim = hidden_dim
        
        # (1) input: bounding box sparse featureë¥¼ Linear Embedding
        self.input_embed = nn.Linear(4, hidden_dim)  # bbox (x1,y1,x2,y2) 4ê°œ
        
        # (2) Transformer Encoder (VTN Backbone)
        encoder_layer = nn.TransformerEncoderLayer(d_model=hidden_dim, nhead=8)
        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=6)

        # (3) Classification Head
        self.classifier = nn.Sequential(
            nn.LayerNorm(hidden_dim),
            nn.Linear(hidden_dim, num_classes)
        )
    
    def forward(self, batch_objects):
        """
        batch_objects: [batch_size, sequence_length, num_objects, 4]
        """
        batch_size, seq_len, num_objects, _ = batch_objects.shape
        
        # object dimensionì„ í•©ì¹˜ì
        x = batch_objects.view(batch_size, seq_len * num_objects, 4)
        
        # (1) bboxë¥¼ hidden_dimìœ¼ë¡œ embedding
        x = self.input_embed(x)  # [batch_size, seq_len*num_objects, hidden_dim]
        
        # (2) Transformer Encoder
        x = x.permute(1, 0, 2)  # [seq_len*num_objects, batch_size, hidden_dim]
        x = self.transformer_encoder(x)  # [seq_len*num_objects, batch_size, hidden_dim]
        x = x.permute(1, 0, 2)  # [batch_size, seq_len*num_objects, hidden_dim]

        # (3) í‰ê·  pooling (ì „ì²´ objects over all frames)
        x = x.mean(dim=1)  # [batch_size, hidden_dim]
        
        # (4) Classification
        out = self.classifier(x)  # [batch_size, num_classes]
        return out
------------------------
## ğŸ“¥ ì…ë ¥ ë°ì´í„° êµ¬ì„±

### 1. ğŸ“¦ bbox ì‹œí€€ìŠ¤
| ë³€ìˆ˜ | ì„¤ëª… | í˜•íƒœ |
|------|------|------|
| `bbox` | í”„ë ˆì„ë³„ ì°¨ëŸ‰/ì‹ í˜¸ë“± ìœ„ì¹˜ ì •ë³´ | `[T, N, 4]` (x, y, w, h) |
| ì „ì²˜ë¦¬ | A/B ì°¨ëŸ‰ + ì‹ í˜¸ë“± ë“± **ì‚¬ê³  ê´€ë ¨ ê°ì²´ë§Œ í•„í„°ë§** ì‚¬ìš© |

### 2. ğŸ§¾ ì‚¬ê³  ë©”íƒ€ ì •ë³´ (ì •ìˆ˜í˜• â†’ `nn.Embedding`)
| ë³€ìˆ˜ëª… | ì„¤ëª… |
|--------|------|
| `accident_place_feature` | ì‚¬ê³  ì¥ì†Œ í˜•íƒœ |
| `vehicle_a_progress_info` | ì°¨ëŸ‰ A ì§„í–‰ ë°©í–¥ |
| `vehicle_b_progress_info` | ì°¨ëŸ‰ B ì§„í–‰ ë°©í–¥ |
| `video_point_of_view` | ë¸”ë°• ì‹œì  ì—¬ë¶€ |
| `damage_location` | í”¼í•´ ì°¨ëŸ‰ ë¶€ìœ„ (1~8 ë°©í–¥) |

---

## ğŸ¯ ì¶œë ¥ (Target)

| ë³€ìˆ˜ | ì„¤ëª… |
|------|------|
| `traffic_accident_type` | ì‚¬ê³  ìœ í˜• í´ë˜ìŠ¤ ë²ˆí˜¸ (í˜„ì¬ 129ê°œ: 0~128) |

> Tìí˜• êµì°¨ë¡œ ë°ì´í„° ê¸°ë°˜ìœ¼ë¡œ 106~128 ì¼ë¶€ í´ë˜ìŠ¤ë§Œ ë¨¼ì € í•™ìŠµ
## ğŸ‹ï¸ í•™ìŠµ ê²°ê³¼

- âœ… `train.pkl`: 1080ê±´, `val.pkl`: 163ê±´ (Tìí˜• êµì°¨ë¡œ ê¸°ì¤€)
- âœ… Loss ê°ì†Œ: **3.09 â†’ 0.14**
- âœ… Validation Accuracy: **98.16%**
- âœ… ë‹¨ì¼ ì¶”ë¡  ì˜ˆì¸¡ ì„±ê³µ: ì˜ˆì¸¡=ì •ë‹µ (ì˜ˆ: 110 â†’ 110)
- âœ… confusion matrixì—ì„œ ëŒ€ë¶€ë¶„ ëŒ€ê°ì„  ì •ë ¬ (ê³ ì •ë°€ ëª¨ë¸)

---
# ğŸš— VTN ê¸°ë°˜ êµí†µì‚¬ê³  ë¶„ì„ ìë™í™” íŒŒì´í”„ë¼ì¸

> ë¸”ë™ë°•ìŠ¤ ì˜ìƒì„ ì…ë ¥í•˜ë©´ YOLO + VTN ê¸°ë°˜ìœ¼ë¡œ ì‚¬ê³  ë©”íƒ€ë°ì´í„°ì™€ íƒ€ì„ë¼ì¸ ë¡œê·¸ë¥¼ ìë™ìœ¼ë¡œ ìƒì„±í•˜ëŠ” í”„ë¡œì íŠ¸ì…ë‹ˆë‹¤.

---

## âœ… ëª©í‘œ

- mp4 ì˜ìƒ â†’ í”„ë ˆì„ ì¶”ì¶œ
- YOLOv8 ê°ì²´ íƒì§€ â†’ `.txt` ì¶œë ¥
- VTN ëª¨ë¸ ì˜ˆì¸¡ â†’ ì‚¬ê³  ìœ í˜• ë° ë©”íƒ€ ì •ë³´ ì¶”ë¡ 
- íƒ€ì„ë¼ì¸ ë¡œê·¸ ìƒì„± â†’ ì¶©ëŒ, ë“±ì¥, ì´íƒˆ ìë™ ê°ì§€

---
# ğŸ§  Traffic Data AI Project (2025.05 ê¸°ì¤€)

ë³¸ í”„ë¡œì íŠ¸ëŠ” êµí†µì‚¬ê³  ì¸ì‹ ë° ì˜ˆì¸¡ì„ ìœ„í•œ YOLO, UFLD, VTN ëª¨ë¸ ê¸°ë°˜ì˜ ë³µí•© AI ì‹œìŠ¤í…œì…ë‹ˆë‹¤.  
ë‹¤ì–‘í•œ í”„ë ˆì„ì›Œí¬ê°€ í†µí•©ë˜ì–´ ìˆìœ¼ë©°, ë””ë ‰í† ë¦¬ëŠ” ê¸°ëŠ¥ ì¤‘ì‹¬ìœ¼ë¡œ ì •ë¦¬ë˜ì–´ ìˆìŠµë‹ˆë‹¤.

---

## ğŸ—‚ï¸ 1. ì´ë¯¸ì§€ ë° YOLO ë¼ë²¨ ê´€ë ¨

| ê²½ë¡œ | ì„¤ëª… | í™•ì¥ì |
|------|------|--------|
| `/home/j-k12e203/traffic_data/train/images/t_junction/` | í•™ìŠµìš© ì´ë¯¸ì§€ | `.png` |
| `/home/j-k12e203/traffic_data/train/labels/t_junction/` | í•™ìŠµìš© YOLO ë¼ë²¨ | `.txt` |
| `/home/j-k12e203/traffic_data/val/images/t_junction/` | ê²€ì¦ìš© ì´ë¯¸ì§€ | `.png` |
| `/home/j-k12e203/traffic_data/val/labels/t_junction/` | ê²€ì¦ìš© YOLO ë¼ë²¨ | `.txt` |
| `/home/j-k12e203/traffic_data/yolo_outputs/t_junction/` | YOLO ì¶”ë¡  ê²°ê³¼ (ì´ë¯¸ì§€ + ë¼ë²¨) | `.jpg`, `.txt` |

---

## ğŸ—‚ï¸ 2. UFLD ì¶”ë¡  ê²°ê³¼ (í˜„ì¬ ì‚¬ìš© ì•ˆ í•¨)

| ê²½ë¡œ | ì„¤ëª… |
|------|------|
| `/home/j-k12e203/traffic_data/ufld_jsons/` | UFLD ì¶”ë¡  ê²°ê³¼ JSON (`lanes`, `h_samples` í¬í•¨) |
| `/home/j-k12e203/traffic_data/Ultra-Fast-Lane-Detection/weights/culane_18.pth` | UFLD ì‚¬ì „í•™ìŠµ ê°€ì¤‘ì¹˜ |

---

## ğŸ—‚ï¸ 3. VTN ê´€ë ¨ í•µì‹¬ ë°ì´í„°

| ê²½ë¡œ | ì„¤ëª… |
|------|------|
| `/home/j-k12e203/traffic_data/merged_analysis/visualized/` | YOLO + UFLD ì‹œê°í™” ê²°ê³¼ |
| `/home/j-k12e203/traffic_data/merged_analysis/timeline_logs/` | VTN timeline log (futureìš©) |
| `/home/j-k12e203/traffic_data/merged_analysis/vtn_inputs/` | ìµœì¢… VTN í•™ìŠµìš© `.jsonl` íŒŒì¼ |

---

## ğŸ—‚ï¸ 4. VTN ì‹œí€€ìŠ¤ ë¼ë²¨ ë°ì´í„°

| ê²½ë¡œ | ì„¤ëª… |
|------|------|
| `/home/j-k12e203/traffic_data/VTN/t_junction/video_jsons/Training/` | ì˜ìƒ í†µí•© json (í›ˆë ¨) |
| `/home/j-k12e203/traffic_data/VTN/t_junction/video_jsons/Validation/` | ì˜ìƒ í†µí•© json (ê²€ì¦) |
| `/home/j-k12e203/traffic_data/VTN/t_junction/image_jsons/` | ì‹œí€€ìŠ¤ë³„ í”„ë ˆì„ YOLO bbox ì¤‘ì‹¬ JSON |

---

## ğŸ—‚ï¸ 5. vehicle_B ê´€ë ¨ ì£¼ìš” ìƒì„± ë°ì´í„°

| ê²½ë¡œ | íŒŒì¼ëª… | ì„¤ëª… |
|------|--------|------|
| `/home/j-k12e203/traffic_data/VTN/t_junction/Scripts/` | `vehicleB_trajectories.json` | bbox ê¶¤ì  (frame_idx, cx, cy, w, h, x, y í¬í•¨) |
| | `vehicleB_directions.json` | polyfit ê¸°ë°˜ ë°©í–¥ ë¶„ë¥˜ ê²°ê³¼ |
| | `vehicleB_direction_hod.json` | HOD ê¸°ë°˜ ë°©í–¥ ì¶”ì • ê²°ê³¼ |
| | `compare_directions_with_progress_info.py` | ë°©í–¥ ì •í™•ë„ ê²€ì¦ ìŠ¤í¬ë¦½íŠ¸ |

---

## ğŸ—‚ï¸ 6. vehicle_B ê¶¤ì  ê¸°ë°˜ í•™ìŠµ ë°ì´í„° (MLP/LSTM)

| ê²½ë¡œ | íŒŒì¼ëª… | ì„¤ëª… |
|------|--------|------|
| `/home/j-k12e203/traffic_data/VTN/t_junction/Scripts/vehicleB_features/` | `vehicleB_feature_dataset.jsonl` | ì›ë³¸ feature í•™ìŠµ ë°ì´í„° (851ê°œ) |
| | `vehicleB_augmented_dataset.jsonl` | from_right ì¤‘ì‹¬ ì¦ê°• (125ê°œ) |
| | `vehicleB_combined_dataset.jsonl` | ë³‘í•©ëœ ìµœì¢… ë°ì´í„°ì…‹ (976ê°œ) |
| | `missing_label_report.txt` | GT ì—†ëŠ” ì‹œí€€ìŠ¤ ë¦¬í¬íŠ¸ |
| | `analyze_feature_label_distribution.py` | label ë¹„ìœ¨ í†µê³„ ì¶œë ¥ |
| | `train_mlp_classifier.py` | MLP í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸ (GPU 2ë²ˆ ì œí•œ í¬í•¨) |
| | `generate_feature_dataset.py` | feature ì¶”ì¶œ jsonl ìƒì„± |
| | `generate_augmented_features.py` | ì¦ê°•ìš© jsonl ìƒì„± |
| | `merge_feature_datasets.py` | jsonl ë³‘í•© ìŠ¤í¬ë¦½íŠ¸ |

---

## ğŸ—‚ï¸ 7. ì‹œê°í™” ê´€ë ¨

| ê²½ë¡œ | ì„¤ëª… |
|------|------|
| `/home/j-k12e203/traffic_data/VTN/t_junction/plots/` | vehicle_B ê¶¤ì  ì‹œê°í™” ì´ë¯¸ì§€ ì €ì¥ ê²½ë¡œ |
| *.png ì˜ˆì‹œ | `00_bb_1_130317_vehicle_35_061.png` â†’ HOD/trajectory ê¸°ë°˜ ì‹œê°í™” ê²°ê³¼ |

---

## âœ… ì°¸ê³ 
- ëª¨ë“  ê²½ë¡œëŠ” **ì ˆëŒ€ê²½ë¡œ** ê¸°ì¤€ `/home/j-k12e203/traffic_data/` ì•„ë˜ êµ¬ì„±ë˜ì–´ ìˆìŠµë‹ˆë‹¤.
- UFLDëŠ” í˜„ì¬ ì‚¬ìš©í•˜ì§€ ì•Šê³  ìˆìœ¼ë©°, ì¶”í›„ í•„ìš” ì‹œ ì¬ì‚¬ìš© ê°€ëŠ¥í•˜ë„ë¡ ê²°ê³¼ë§Œ ë³´ì¡´ë˜ì–´ ìˆìŠµë‹ˆë‹¤.
- í•™ìŠµ ë° ì¶”ë¡  ì‹œ GPU 2ë²ˆë§Œ ì‚¬ìš©í•˜ë„ë¡ ëª¨ë“  ìŠ¤í¬ë¦½íŠ¸ì— ëª…ì‹œì  ì œí•œì´ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤.

ê²½ë¡œ ì„¤ê³„ì— ëŒ€í•´ì„œ ë°©í–¥ì„± ì¡ìŒ
masking ì§„í–‰í•¨.
