#!/usr/bin/env python3
import os
import cv2
import numpy as np
import pandas as pd
from glob import glob
from scipy.signal import medfilt
from scipy.ndimage import gaussian_filter1d
import shutil
import time
import logging
import subprocess
from fastapi import HTTPException
from ...config import Config

# ë¡œê±° ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

MOG2_HISTORY = 200
MOG2_VAR_THRESH = 16
STEP = 15
CALIB_FRAMES = 60
MED_KSIZE = 11
GAUSS_SIGMA = 2
COLL_DIFF = 5.0
COLL_SMOOTH_WIN = 11
RANSAC_MIN_QUALITY = 0.3
RANSAC_REPROJ_THRESH = 4.0
METHODS = ["sparse_lk", "dense_far", "ransac_affine"]

def check_gpu_available():
    try:
        res = subprocess.run(
            ["nvidia-smi", "--query-gpu=name", "--format=csv,noheader"],
            stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True, timeout=5
        )
        return res.returncode == 0 and bool(res.stdout.strip())
    except:
        return False

def estimate_vehicleA_trajectory(analysis_result):
    # í™˜ê²½ ì„¤ì •
    os.environ["CUDA_DEVICE_ORDER"]   = Config.CUDA_DEVICE_ORDER
    os.environ["CUDA_VISIBLE_DEVICES"] = Config.CUDA_VISIBLE_DEVICES
    os.environ["OMP_NUM_THREADS"]     = "2"
    os.environ["MKL_NUM_THREADS"]     = "2"

    # GPU í™•ì¸ ë° ì´ˆê¸°í™”
    if not check_gpu_available():
        raise HTTPException(500, "ì°¨ëŸ‰A ê¶¤ì  ì¶”ì •ì— í•„ìš”í•œ GPUê°€ ê°ì§€ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    cv2.cuda.setDevice(0)
    logger.info("ğŸš€ GPU ì‚¬ìš©: ì¥ì¹˜ #0")

    # ê²½ë¡œ ì¤€ë¹„
    user_id    = analysis_result["userId"]
    video_id   = analysis_result["videoId"]
    frames_dir = analysis_result["frames_dir"]
    out_dir    = os.path.join(Config.TRAJECTORY_PATH, str(user_id), str(video_id))
    if os.path.exists(out_dir):
        shutil.rmtree(out_dir)
    os.makedirs(out_dir, exist_ok=True)

    # í”„ë ˆì„ ë¡œë“œ
    jpgs = sorted(glob(f"{frames_dir}/*.jpg"))
    if not jpgs:
        return {"status":"error","message":"No frames found"}
    grays_full = [cv2.cvtColor(cv2.imread(p), cv2.COLOR_BGR2GRAY) for p in jpgs]
    grays = grays_full.copy()
    N, H, W = len(grays), *grays[0].shape

    # ë°°ê²½ ì°¨ë¶„
    bgsub_flow  = cv2.createBackgroundSubtractorMOG2(MOG2_HISTORY, MOG2_VAR_THRESH, False)
    prev_fgmask = np.zeros((H, W), dtype=bool)

    # í¬ì¸íŠ¸ ê·¸ë¦¬ë“œ
    yy, xx   = np.mgrid[0:H:STEP, 0:W:STEP]
    pts_all  = np.vstack((xx.ravel(), yy.ravel())).T.astype(np.float32).reshape(-1,1,2)

    # GPU ì˜µí‹°ì»¬ í”Œë¡œìš° ê°ì²´
    stream    = cv2.cuda_Stream()
    sparse_lk = cv2.cuda.SparsePyrLKOpticalFlow.create(winSize=(15,15), maxLevel=2, iters=10, useInitialFlow=False)
    dense_far = cv2.cuda.FarnebackOpticalFlow.create(numLevels=3, pyrScale=0.5,
                                                     fastPyramids=False, winSize=15,
                                                     numIters=3, polyN=5, polySigma=1.2, flags=0)

    raw, qualities = {}, {}

    for name in METHODS:
        logger.info(f"[{name}] ì˜µí‹°ì»¬ í”Œë¡œìš° ê³„ì‚° ì‹œì‘ (GPU ì‚¬ìš©)")
        dxs, dys, qs = [0.0], [0.0], [0.0]
        prev_gray     = grays[0]
        prev_fgmask[:] = False
        prev_gray_gpu = cv2.cuda_GpuMat()
        prev_gray_gpu.upload(prev_gray)

        for idx, gray in enumerate(grays[1:], 1):
            # ì§„í–‰ë¥  ë¡œê·¸
            if idx % max(1, N//10) == 0:
                logger.info(f"[{name}] ì§„í–‰ë¥ : {idx}/{N} ({idx/N*100:.1f}%)")

            fg     = bgsub_flow.apply(gray, learningRate=0.005)
            fgmask = fg >= 128
            new_obj= fgmask & ~prev_fgmask
            prev_fgmask[:] = fgmask
            mask   = (~fgmask & ~new_obj)

            dx = dy = q = 0.0

            if name == "sparse_lk":
                sel = mask[::STEP, ::STEP].ravel()
                pts = pts_all[sel]
                if pts.size:
                    pts1     = pts.reshape(1, -1, 2).astype(np.float32)
                    p0_gpu   = cv2.cuda_GpuMat(); p0_gpu.upload(pts1)
                    gray_gpu = cv2.cuda_GpuMat(); gray_gpu.upload(gray)
                    next_pts = cv2.cuda_GpuMat()
                    status   = cv2.cuda_GpuMat()
                    err      = cv2.cuda_GpuMat()

                    sparse_lk.calc(prev_gray_gpu, gray_gpu, p0_gpu, next_pts, status, err, stream)
                    stream.waitForCompletion()
                    p1 = next_pts.download()
                    st = status.download()

                    if st is None or st.size == 0:
                        dx = dy = q = 0.0
                    else:
                        ok       = (st.flatten() == 1)
                        q        = ok.sum() / len(pts1[0])
                        if ok.any():
                            old = pts1[0][ok]
                            new = p1[0][ok]
                            flow = new - old
                            dx, dy = -flow.mean(axis=0)

            elif name == "dense_far":
                gray_gpu = cv2.cuda_GpuMat(); gray_gpu.upload(gray)
                flow_gpu = dense_far.calc(prev_gray_gpu, gray_gpu, None, stream)
                stream.waitForCompletion()
                flow     = flow_gpu.download()
                fx, fy   = flow[...,0][mask], flow[...,1][mask]
                q        = np.isfinite(fx).sum() / (mask.sum() or 1)
                if fx.size:
                    dx, dy = -np.median(fx), -np.median(fy)

            else:  # ransac_affine
                pts1     = pts_all.reshape(1, -1, 2).astype(np.float32)
                p_gpu    = cv2.cuda_GpuMat(); p_gpu.upload(pts1)
                gray_gpu = cv2.cuda_GpuMat(); gray_gpu.upload(gray)
                next_pts = cv2.cuda_GpuMat()
                status   = cv2.cuda_GpuMat()
                err      = cv2.cuda_GpuMat()

                sparse_lk.calc(prev_gray_gpu, gray_gpu, p_gpu, next_pts, status, err, stream)
                stream.waitForCompletion()
                p1 = next_pts.download()
                st = status.download()

                if st is None or st.size == 0:
                    dx = dy = q = 0.0
                else:
                    ok       = (st.flatten() == 1)
                    q        = ok.sum() / len(pts_all)
                    if q >= RANSAC_MIN_QUALITY and ok.sum() >= 3:
                        old = pts_all[ok].reshape(-1,2)
                        new = p1[0][ok].reshape(-1,2)
                        M, _ = cv2.estimateAffinePartial2D(old, new,
                                                          method=cv2.RANSAC,
                                                          ransacReprojThreshold=RANSAC_REPROJ_THRESH)
                        if M is not None:
                            dx, dy = -M[0,2], -M[1,2]
                        else:
                            flow = new - old
                            dx, dy = -np.median(flow, axis=0)

            dxs.append(float(dx))
            dys.append(float(dy))
            qs.append(float(q))
            prev_gray_gpu.upload(gray)

        raw[name]       = (np.array(dxs), np.array(dys))
        qualities[name] = np.array(qs)
        pd.DataFrame({
            f"{name}_dx":      dxs,
            f"{name}_dy":      dys,
            f"{name}_quality": qs
        }).to_csv(f"{out_dir}/{name}_raw_flow.csv", index_label="frame")

    # í›„ì²˜ë¦¬ ë° ì €ì¥
    proc, colls = {}, {}
    for name, (dx, dy) in raw.items():
        V0     = np.vstack([dx[1:CALIB_FRAMES], dy[1:CALIB_FRAMES]]).T
        u      = V0.mean(axis=0); u /= (np.linalg.norm(u) + 1e-8)
        l      = np.array([-u[1], u[0]])
        lat    = np.stack([dx, dy], axis=1).dot(l); lat[:CALIB_FRAMES] = 0.0
        lat_med= medfilt(lat, kernel_size=MED_KSIZE)
        lat_sm = gaussian_filter1d(lat_med, sigma=GAUSS_SIGMA)
        traj   = np.cumsum(lat_sm)
        d      = np.abs(np.diff(traj, prepend=traj[0]))
        s      = np.convolve(d, np.ones(COLL_SMOOTH_WIN)/COLL_SMOOTH_WIN, mode="same")
        coll   = int(np.argmax(s > COLL_DIFF))
        proc[name]  = traj
        colls[name] = coll
        pd.DataFrame({
            f"{name}_lat_raw":    lat,
            f"{name}_lat_med":    lat_med,
            f"{name}_lat_smooth": lat_sm,
            f"{name}_traj":       traj
        }).to_csv(f"{out_dir}/{name}_processed.csv", index_label="frame")

    # ì•™ìƒë¸”
    all_traj = np.vstack([proc[m] for m in METHODS])
    ens_traj = np.median(all_traj, axis=0)
    ens_coll = int(pd.Series(list(colls.values())).median())
    pd.DataFrame({
        **{f"{m}_traj": proc[m] for m in METHODS},
        "ensemble_traj":  ens_traj,
        "collision_idx":  ens_coll
    }).to_csv(os.path.join(out_dir, "ensemble_trajectory.csv"), index_label="frame")

    # ìƒˆ ì½”ë“œ ë¡œì§ ì¶”ê°€: first_seenê³¼ accident ì‚¬ì´ì˜ ì°¨ëŸ‰A ê¶¤ì  ì¶”ì¶œ
    try:
        # 1) íƒ€ì„ë¼ì¸ ì •ë³´ í™•ì¸
        if "timeline_analysis" not in analysis_result:
            logger.warning("íƒ€ì„ë¼ì¸ ë°ì´í„°ê°€ ì—†ì–´ ì°¨ëŸ‰A ì„¸ë¶€ ê¶¤ì ì„ ê³„ì‚°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            # ë””ë²„ê¹…: ì‚¬ìš© ê°€ëŠ¥í•œ í‚¤ ë¡œê¹…
            logger.info(f"ì‚¬ìš© ê°€ëŠ¥í•œ í‚¤: {list(analysis_result.keys())}")
        else:
            # ë””ë²„ê¹…: íƒ€ì„ë¼ì¸ ë°ì´í„° êµ¬ì¡° ë¡œê¹…
            timeline_data = analysis_result["timeline_analysis"]
            logger.info(f"íƒ€ì„ë¼ì¸ ë°ì´í„° í‚¤: {list(timeline_data.keys())}")
            
            # 2) ì²« ë“±ì¥ & ì‚¬ê³  ì‹œì  ì¶”ì¶œ
            try:
                # generate_timeline_log ë°˜í™˜ êµ¬ì¡° í™•ì¸: "timeline"."event_timeline"
                timeline_data = analysis_result["timeline_analysis"]
                
                # íƒ€ì„ë¼ì¸ì—ì„œ event_timeline ê°€ì ¸ì˜¤ê¸°
                event_timeline = None
                
                # 1. í‘œì¤€ êµ¬ì¡° ì‹œë„: timeline.event_timeline
                if "timeline" in timeline_data and "event_timeline" in timeline_data["timeline"]:
                    event_timeline = timeline_data["timeline"]["event_timeline"]
                    logger.info("í‘œì¤€ êµ¬ì¡°ì—ì„œ ì´ë²¤íŠ¸ íƒ€ì„ë¼ì¸ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤")
                # 2. ëŒ€ì²´ êµ¬ì¡° ì‹œë„: event_timeline
                elif "event_timeline" in timeline_data:
                    event_timeline = timeline_data["event_timeline"]
                    logger.info("ëŒ€ì²´ êµ¬ì¡°ì—ì„œ ì´ë²¤íŠ¸ íƒ€ì„ë¼ì¸ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤")
                # 3. accident_frame, first_seen_idx ì •ë³´ ì‚¬ìš© ì‹œë„
                elif "timeline" in timeline_data and "accident_frame_idx" in timeline_data["timeline"] and "first_seen_idx" in timeline_data["timeline"]:
                    logger.info("íƒ€ì„ë¼ì¸ì—ì„œ ì§ì ‘ í”„ë ˆì„ ì¸ë±ìŠ¤ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤")
                    accident = timeline_data["timeline"]["accident_frame_idx"]
                    first_seen = timeline_data["timeline"]["first_seen_idx"]
                    
                    # ì²˜ë¦¬ í”Œë˜ê·¸ ì„¤ì • - ë‹¤ìŒ ë‹¨ê³„ë¡œ ì§„í–‰
                    continue_processing = True
                else:
                    logger.warning("ì§€ì›ë˜ëŠ” íƒ€ì„ë¼ì¸ êµ¬ì¡°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
                    event_timeline = []
                    continue_processing = False
                
                # event_timelineì„ ì‚¬ìš©í•œ ì²˜ë¦¬ (ì´ë²¤íŠ¸ íƒ€ì„ë¼ì¸ì´ ìˆëŠ” ê²½ìš°)
                if event_timeline and "continue_processing" not in locals():
                    logger.info(f"ì´ë²¤íŠ¸ íƒ€ì„ë¼ì¸ì—ì„œ í”„ë ˆì„ ì¸ë±ìŠ¤ ì¶”ì¶œ (ì´ë²¤íŠ¸ ìˆ˜: {len(event_timeline)})")
                    # ì´ë²¤íŠ¸ ì¶œë ¥
                    event_types = [e.get('event', 'unknown') for e in event_timeline]
                    logger.info(f"ì´ë²¤íŠ¸ ìœ í˜•: {event_types}")
                    
                    try:
                        first_seen = next(e['frame_idx'] for e in event_timeline if e['event'] == "vehicle_B_first_seen")
                        accident = next(e['frame_idx'] for e in event_timeline if e['event'] == "accident_estimated")
                        continue_processing = True
                    except StopIteration:
                        logger.warning("íƒ€ì„ë¼ì¸ì—ì„œ í•„ìš”í•œ ì´ë²¤íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
                        continue_processing = False
                elif "continue_processing" not in locals():
                    logger.warning("ì´ë²¤íŠ¸ íƒ€ì„ë¼ì¸ì´ ë¹„ì–´ ìˆê±°ë‚˜ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
                    continue_processing = False
                
                # ê³µí†µ ì²˜ë¦¬ ë¡œì§ - í•„ìš”í•œ ë°ì´í„°ê°€ ì¤€ë¹„ëœ ê²½ìš°ë§Œ ì‹¤í–‰
                if "continue_processing" in locals() and continue_processing:
                    # 3) ë¶€í˜¸ ë°˜ì „ ë° ì²« ë“±ì¥-ì‚¬ê³  êµ¬ê°„ ì¶”ì¶œ
                    ego_lat = -ens_traj  # ë¶€í˜¸ ë°˜ì „
                    ego_pos = np.cumsum(ego_lat)
                    
                    try:
                        # ìŠ¬ë¼ì´ì‹± ê°€ëŠ¥í•œì§€ í™•ì¸
                        if first_seen <= accident and first_seen < len(ego_pos) and accident < len(ego_pos):
                            # ìŠ¬ë¼ì´ì‹± (first_seenë¶€í„° accidentê¹Œì§€)
                            sub_pos = ego_pos[first_seen:accident+1].copy()
                            
                            # ì²« ë“±ì¥ ìœ„ì¹˜ë¥¼ 0ìœ¼ë¡œ ë§ì¶”ê¸°
                            sub_pos = sub_pos - sub_pos[0]
                            
                            # ì¸ë±ìŠ¤ ìƒì„± (first_seenë¶€í„° accidentê¹Œì§€)
                            idx = np.arange(first_seen, accident+1)
                            
                            # 4) ì €ì¥ - ìƒˆ ì½”ë“œì™€ ë™ì¼í•œ í˜•ì‹ìœ¼ë¡œ
                            ego_csv_path = os.path.join(out_dir, "vehicle_A_trajectory.csv")
                            os.makedirs(os.path.dirname(ego_csv_path), exist_ok=True)
                            
                            # DataFrame ìƒì„± í›„ ì €ì¥
                            df_out = pd.DataFrame({"ego_pos": sub_pos}, index=idx)
                            df_out.index.name = "frame"
                            df_out.to_csv(ego_csv_path)
                            
                            logger.info(f"âœ… ì°¨ëŸ‰A ê¶¤ì  ì €ì¥ ì™„ë£Œ: {ego_csv_path}")
                            logger.info(f"   í”„ë ˆì„: {first_seen} â†’ {accident}")
                            logger.info(f"   ì´ ì´ë™ê±°ë¦¬: {sub_pos[-1]:.2f} px")
                            
                            # ê²°ê³¼ì— ì„¸ë¶€ ì •ë³´ ì¶”ê°€
                            analysis_result["vehicle_A_trajectory"] = {
                                "csv_path": ego_csv_path,
                                "first_seen": int(first_seen),
                                "accident": int(accident),
                                "total_displacement": float(sub_pos[-1])
                            }
                        else:
                            logger.warning(f"í”„ë ˆì„ ë²”ìœ„ ì˜¤ë¥˜: first_seen={first_seen}, accident={accident}, len(ego_pos)={len(ego_pos)}")
                    except Exception as e:
                        logger.error(f"ì°¨ëŸ‰A ê¶¤ì  ìŠ¬ë¼ì´ì‹± ì˜¤ë¥˜: {str(e)}")
            except Exception as e:
                logger.error(f"ì°¨ëŸ‰A ì„¸ë¶€ ê¶¤ì  ê³„ì‚° ì¤‘ ì˜¤ë¥˜: {str(e)}")
    except Exception as e:
        logger.error(f"ì°¨ëŸ‰A ì„¸ë¶€ ê¶¤ì  ê³„ì‚° ì¤‘ ì˜¤ë¥˜: {str(e)}")
    
    # ê²°ê³¼ ë°˜í™˜
    return {
        "ensemble_trajectory": ens_traj.tolist(),
        "collision_idx":       ens_coll,
        "trajectory_methods":  METHODS,
        "output_dir":          out_dir,
        "csv_path":            os.path.join(out_dir, "ensemble_trajectory.csv"),
        "status":              "success",
        "gpu_used":            True
    }
